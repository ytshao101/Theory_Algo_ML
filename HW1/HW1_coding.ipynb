{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b15c0f",
   "metadata": {},
   "source": [
    "# 3 Classifiers and Metrics - Coding\n",
    "## 3.1 Calculate the value of g(x) and choose the threshold to minimize misclassification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e236d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8468b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a dataframe with features and labels\n",
    "data = {'Age': [20, 18, 11, 31, 19, 21, 44, 15, 16, 17],\n",
    "        'likeRowing': [1, 1, 0, 0, 1, 1, 1, 1, 0, 1],\n",
    "        'Experience': [0, 1, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "        'Income': [20, 33, 21, 18, 7, 10, 23, 16, 15, 6],\n",
    "        'Y': [0, 0, 1, 1, 1, 0, 1, 0, 1, 0]}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "25967769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function g(x) and f(x)\n",
    "theta = np.array([0.05, -3, 2.1, 0.008])\n",
    "theta_0 = np.full([1, 10], 0.3)\n",
    "\n",
    "def g(x):\n",
    "    \n",
    "    result = x @ theta.transpose() + theta_0\n",
    "    \n",
    "    return result.tolist()[0]\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    \n",
    "    result = (mt.exp(x) - mt.exp(-x))/(mt.exp(x) + mt.exp(-x))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \n",
    "    result = tanh(g(x))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0e071b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Age</th>\n",
       "      <th>likeRowing</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Y</th>\n",
       "      <th>g(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Age  likeRowing  Experience  Income  Y   g(x)\n",
       "0      8   16           0           1      15  1  3.320\n",
       "1      2   11           0           1      21  1  3.118\n",
       "2      3   31           0           0      18  1  1.994\n",
       "3      1   18           1           1      33  0  0.564\n",
       "4      4   19           1           1       7  1  0.406\n",
       "5      7   15           1           1      16  0  0.278\n",
       "6      6   44           1           0      23  1 -0.316\n",
       "7      0   20           1           0      20  0 -1.540\n",
       "8      5   21           1           0      10  0 -1.570\n",
       "9      9   17           1           0       6  0 -1.802"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate g(x)\n",
    "x = np.array(df.iloc[:, 0:4])\n",
    "df1 = df\n",
    "gx = g(x)\n",
    "df1['g(x)'] = gx\n",
    "df1\n",
    "df1_sortby_g = df1.sort_values(by='g(x)', ascending=False)\n",
    "df1_sortby_g.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d3755b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate misclassification error for each threshold\n",
    "def MisClassificationError(df, classifier):  # Note: pass a string to 'classifier'\n",
    "    \n",
    "    df_sorted = df.sort_values(by=classifier, ascending=False)\n",
    "    \n",
    "    mis_errors = []\n",
    "    f1scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    N = df.shape[0]\n",
    "\n",
    "    for idx in df_sorted.index:\n",
    "\n",
    "        pred_1 = df_sorted['Y'].iloc[:idx+1]\n",
    "        pred_0 = df_sorted['Y'].iloc[idx+1:]\n",
    "\n",
    "        TP = sum(pred_1)\n",
    "        FP = len(pred_1) - TP\n",
    "        FN = sum(pred_0)\n",
    "        TN = len(pred_0) - FN\n",
    "\n",
    "        mis_error = (FP + FN) / N\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        mis_errors.append(mis_error)\n",
    "        f1scores.append(f1score)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    error_sort = np.sort(mis_errors)\n",
    "    error_args = np.argsort(mis_errors)\n",
    "    \n",
    "    return error_sort, error_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0e79a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification errors and index using g(x) as classifier:\n",
      " (array([0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.5]), array([1, 4, 6, 2, 3, 5, 8, 0, 7, 9]))\n",
      "thresholds that will achieve the minimum misclassification error:\n",
      " 3    1.994\n",
      "7    0.278\n",
      "0   -1.540\n",
      "Name: g(x), dtype: float64\n",
      "minimum misclassification error: 0.2\n"
     ]
    }
   ],
   "source": [
    "df = df1\n",
    "classifier = 'g(x)'\n",
    "g_min_err = MisClassificationError(df, classifier)\n",
    "print('misclassification errors and index using g(x) as classifier:\\n', g_min_err)\n",
    "g_arg_min_err = g_min_err[1][:3]\n",
    "thresholds_g = df1_sortby_g['g(x)'].iloc[g_arg_min_err+1]\n",
    "print('thresholds that will achieve the minimum misclassification error:\\n', thresholds_g)\n",
    "print('minimum misclassification error:', np.min(g_min_err[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179fdaa",
   "metadata": {},
   "source": [
    "The thresholds (denote as T) that will achieve the minimum classification error are:  \n",
    "$$\n",
    "T = 1.994 \\ or \\ 0.278 \\ or \\ -1.540\n",
    "$$\n",
    "the minimum misclassification error is $\\frac{FP+FN}{N} = \\frac{2}{10}=0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f50cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1607a38e",
   "metadata": {},
   "source": [
    "## 3.2 Calculate f(x), choose the threshold to minimize misclassification error, and compute its cofusion matrix, precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9e6fa91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>likeRowing</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Y</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>f(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.320</td>\n",
       "      <td>0.997389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.118</td>\n",
       "      <td>0.996092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994</td>\n",
       "      <td>0.963601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.510939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.385071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.271053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.305886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-0.912120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.570</td>\n",
       "      <td>-0.917026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.802</td>\n",
       "      <td>-0.947013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  likeRowing  Experience  Income  Y   g(x)      f(x)\n",
       "8   16           0           1      15  1  3.320  0.997389\n",
       "2   11           0           1      21  1  3.118  0.996092\n",
       "3   31           0           0      18  1  1.994  0.963601\n",
       "1   18           1           1      33  0  0.564  0.510939\n",
       "4   19           1           1       7  1  0.406  0.385071\n",
       "7   15           1           1      16  0  0.278  0.271053\n",
       "6   44           1           0      23  1 -0.316 -0.305886\n",
       "0   20           1           0      20  0 -1.540 -0.912120\n",
       "5   21           1           0      10  0 -1.570 -0.917026\n",
       "9   17           1           0       6  0 -1.802 -0.947013"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['f(x)'] = df1['g(x)'].apply(tanh)\n",
    "df1_sortby_f = df1.sort_values(by='f(x)', ascending=False)\n",
    "df1_sortby_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ea08d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification errors and index using f(x) as classifier:\n",
      " (array([0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.5]), array([1, 4, 6, 2, 3, 5, 8, 0, 7, 9]))\n",
      "thresholds that will achieve the minimum misclassification error:\n",
      " 3    0.963601\n",
      "7    0.271053\n",
      "0   -0.912120\n",
      "Name: f(x), dtype: float64\n",
      "minimum misclassification error: 0.2\n"
     ]
    }
   ],
   "source": [
    "df = df1\n",
    "classifier = 'f(x)'\n",
    "f_min_err = MisClassificationError(df, classifier)\n",
    "print('misclassification errors and index using f(x) as classifier:\\n', f_min_err)\n",
    "f_arg_min_err = f_min_err[1][:3]\n",
    "thresholds_f = df1_sortby_f['f(x)'].iloc[f_arg_min_err+1]\n",
    "print('thresholds that will achieve the minimum misclassification error:\\n', thresholds_f)\n",
    "print('minimum misclassification error:', np.min(f_min_err[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabafd3",
   "metadata": {},
   "source": [
    "The thresholds (denote as T) that will minimize the classification error are:  \n",
    "$$\n",
    "T = 0.9636 \\ or \\ 0.2720 \\ or \\ -0.9121\n",
    "$$\n",
    "the minimum misclassification error is $\\frac{FP+FN}{N} = \\frac{2}{10}=0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9410f39",
   "metadata": {},
   "source": [
    "Take $T = 0.9636$ as an example.  \n",
    "$$TP=3,\\ TN=5,\\ FP=0,\\ FN=2$$\n",
    "Confusion matrix:    \n",
    "   \n",
    "|         | $y=1$   |   $y=0$  |\n",
    "| :--------:  | :-----: | :-----: |\n",
    "| $\\hat{y}=1$  |  3     |   0    |\n",
    "| $\\hat{y}=0$ |  2     |  5     |\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{predicted positive} = 1 \\\\\n",
    "Recall = \\frac{TP}{Positive} = \\frac{3}{5} \\\\\n",
    "F1score = 2\\frac{Precision * Recall}{Precision + Recall}= \\frac{3}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c0877",
   "metadata": {},
   "source": [
    "## 3.3 Plot ROC curve of f(x) and the points that represent decision points with the minimum classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "45f20ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 0.6, 0.6, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.8, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd8b47c45b0>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sorty_reindex = df1_sortby_f.reset_index()\n",
    "\n",
    "TPR_list = []\n",
    "FPR_list = []\n",
    "pos = neg = 5\n",
    "for i in list(df_sorty_reindex.index):\n",
    "    \n",
    "    TP = sum(df_sorty_reindex['Y'].iloc[:i+1])  \n",
    "    FP = i + 1 - TP\n",
    "    TPR = TP / pos\n",
    "    FPR = FP / neg\n",
    "    TPR_list.append(TPR)\n",
    "    FPR_list.append(FPR)\n",
    "    \n",
    "\n",
    "print(TPR_list)\n",
    "print(FPR_list)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(FPR_list, TPR_list);\n",
    "plt.grid(True, linestyle='--', alpha = .5)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC curve of f(x)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# plot the thresholds\n",
    "fpr_threshold = [0, 0.2, 0.4]\n",
    "tpr_threshold = [0.6, 0.8, 1]\n",
    "plt.scatter(fpr_threshold, tpr_threshold, c='r') \n",
    "plt.legend(['ROC curve','thresholds that minimize classification error'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fc781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b745eaf",
   "metadata": {},
   "source": [
    "# 5 Classification with KNN and Decision Tree\n",
    "## 5.2 Use two decision tree packages, report F1 score and tune parameter with K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "141d45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f904967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '/Users/shaoyutong/Library/Mobile Documents/com~apple~CloudDocs/CS671-ML/HW/NEW-HW1/carseats_train.csv')\n",
    "df_test = pd.read_csv(\n",
    "    '/Users/shaoyutong/Library/Mobile Documents/com~apple~CloudDocs/CS671-ML/HW/NEW-HW1/carseats_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1938bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "df_train1 = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c105a7f",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0803075c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing--encoding strings with binary variables\n",
    "# encoding ShelveLoc\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "sl_train = np.array(df_train['ShelveLoc']).reshape(-1,1)\n",
    "sl_test = np.array(df_test['ShelveLoc']).reshape(-1,1)\n",
    "encoder.fit(sl_train)\n",
    "encoder.categories_\n",
    "df_train[['sl_bad','sl_good','sl_medium']]=encoder.transform(sl_train).toarray()\n",
    "df_test[['sl_bad','sl_good','sl_medium']]=encoder.transform(sl_test).toarray()\n",
    "\n",
    "# encoding Urban, US\n",
    "urban_train = pd.get_dummies(df_train['Urban'], prefix='urban')\n",
    "urban_train.head()\n",
    "urban_test = pd.get_dummies(df_test['Urban'], prefix='urban')\n",
    "\n",
    "US_train = pd.get_dummies(df_train['US'], prefix='us')\n",
    "US_train.head()\n",
    "US_test = pd.get_dummies(df_test['US'], prefix='us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b705a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>sl_bad</th>\n",
       "      <th>sl_good</th>\n",
       "      <th>sl_medium</th>\n",
       "      <th>urban_No</th>\n",
       "      <th>urban_Yes</th>\n",
       "      <th>us_No</th>\n",
       "      <th>us_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>425</td>\n",
       "      <td>120</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>118</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price  Age  Education  \\\n",
       "0      0        117     100            4         466     97   55         14   \n",
       "1      0        141      64            3         340    128   38         13   \n",
       "2      0        115     105            0          45    108   71         15   \n",
       "3      1        136      81           15         425    120   67         10   \n",
       "4      1        107     117           11         148    118   52         18   \n",
       "\n",
       "   sl_bad  sl_good  sl_medium  urban_No  urban_Yes  us_No  us_Yes  \n",
       "0     0.0      0.0        1.0         0          1      0       1  \n",
       "1     1.0      0.0        0.0         0          1      1       0  \n",
       "2     0.0      0.0        1.0         0          1      1       0  \n",
       "3     0.0      1.0        0.0         0          1      0       1  \n",
       "4     0.0      1.0        0.0         0          1      0       1  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_urban_train = pd.merge(urban_train, US_train, left_index=True, right_index=True)\n",
    "train = pd.merge(df_train, us_urban_train, left_index=True, right_index=True)\n",
    "train1 = train.drop(columns=['ShelveLoc','US','Urban'])\n",
    "train1\n",
    "us_urban_test = pd.merge(urban_test, US_test, left_index=True, right_index=True)\n",
    "test = pd.merge(df_test, us_urban_test, left_index=True, right_index=True)\n",
    "test1 = test.drop(columns=['ShelveLoc','US','Urban'])\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72d332",
   "metadata": {},
   "source": [
    "## 1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data (df_train)\n",
    "x_train = train1.drop(columns=['Sales'])\n",
    "y_train = train1['Sales']\n",
    "clf = DecisionTreeClassifier()\n",
    "clf_gini = clf.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "x_test = test1.drop(columns='Sales')\n",
    "y_test = test1['Sales']\n",
    "y_pred = clf.predict(x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# report f1-score\n",
    "# f1_score(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f237aa",
   "metadata": {},
   "source": [
    "### 1.1 Compute F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b4b88a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1Score(y_true, y_pred):\n",
    "    \n",
    "    # initialization\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for true in y_true:\n",
    "        \n",
    "        for pred in y_pred:\n",
    "    \n",
    "            if pred == 1:\n",
    "\n",
    "                if true == 1:\n",
    "                    TP += 1\n",
    "\n",
    "                elif true == 0:\n",
    "                    FP += 1\n",
    "\n",
    "            if pred == 0:\n",
    "\n",
    "                if true == 1:\n",
    "                    FN += 1\n",
    "\n",
    "                elif true == 0:\n",
    "                    TN += 1\n",
    "\n",
    "    confusion_matrix = np.array([[TP, FP],[FN, TN]])\n",
    "    TPR_recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1 = 2 * (precision * TPR_recall) / (precision + TPR_recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "# F1Score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5c6bd",
   "metadata": {},
   "source": [
    "### 1.2 Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a29552e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold Cross validation\n",
    "\n",
    "def CrossValidation(train_set, test_set, K, max_depths, target_label):\n",
    "    \n",
    "    # initialization\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    f1_score_all = []\n",
    "    #K-fold\n",
    "    kf = KFold(n_splits=K)\n",
    "    \n",
    "#     for pname, pvalues in parameters.items(): # interate each parameter and value list\n",
    "#         f1_param_list = []  # create a list to store the f1 score of each parameter\n",
    "        \n",
    "    for v in max_depths:  # for each parameter, interate values of that specific parameter\n",
    "\n",
    "        f1_each_depth_list = []  # list of f1 score for each value of one parameter\n",
    "\n",
    "        for train_idx, test_idx in kf.split(train_set): \n",
    "            # for each value, run k-fold CV\n",
    "\n",
    "            train = train_set.iloc[train_idx]\n",
    "            x_train = train.drop(columns=target_label)\n",
    "            y_train = train[target_label]\n",
    "\n",
    "            test = train_set.iloc[test_idx]\n",
    "            x_test = test.drop(columns=target_label)\n",
    "            y_test = test[target_label]\n",
    "\n",
    "            Dtree = DecisionTreeClassifier(max_depth=v)  # modify parameter and train model\n",
    "            clf = Dtree.fit(x_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(x_test)  # predict with newly-trained model\n",
    "            y_true = y_test\n",
    "\n",
    "            f1 = F1Score(y_true, y_pred)  # call the f1 function created above\n",
    "\n",
    "            f1_each_depth_list.append(f1)\n",
    "              # store f1 scores in a list for each parameter value \n",
    "\n",
    "        f1_depth = np.average(f1_each_depth_list) # f1 score of one param value\n",
    "        f1_score_all.append(f1_depth)   # \n",
    "        \n",
    "    f1_dict = {\n",
    "        'max_depths': max_depths,\n",
    "        'f1_score': f1_score_all\n",
    "    }\n",
    "    df_f1 = pd.DataFrame(f1_dict)\n",
    "    arg_best = np.argsort(f1_score_all)[-1]\n",
    "    best_depth = max_depths[arg_best]\n",
    "    best_f1 = np.sort(f1_score_all)[-1]\n",
    "        \n",
    "    return best_depth, best_f1, df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "90cd4a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,\n",
       " 0.3881671769157439,\n",
       "     max_depths  f1_score\n",
       " 0            2  0.260535\n",
       " 1            3  0.291266\n",
       " 2            4  0.332741\n",
       " 3            5  0.326365\n",
       " 4            6  0.366840\n",
       " 5            7  0.374136\n",
       " 6            8  0.368940\n",
       " 7            9  0.386816\n",
       " 8           10  0.386379\n",
       " 9           11  0.381974\n",
       " 10          12  0.366365\n",
       " 11          13  0.374312\n",
       " 12          14  0.380966\n",
       " 13          15  0.363467\n",
       " 14          16  0.375719\n",
       " 15          17  0.388074\n",
       " 16          18  0.385409\n",
       " 17          19  0.388167)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = np.arange(2,20)\n",
    "CrossValidation(train1, test1, 10, max_depths=depths, target_label='Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e5ce05c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(max_depth=3),\n",
       "             param_grid={'max_depth': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19]),\n",
       "                         'min_samples_leaf': [1, 5, 10, 15, 20, 50, 75, 100]})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using GridSearchCV to tune parameter\n",
    "depths = np.arange(0,20,1)\n",
    "leafs = [1, 5, 10, 15, 20, 50, 75, 100]\n",
    "param = {'max_depth': depths,\n",
    "        'min_samples_leaf': leafs}\n",
    "DT_gscv = GridSearchCV(estimator=clf, param_grid=param, cv=10)\n",
    "DT_gscv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa51e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737807881773399 {'max_depth': 8, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "print(DT_gscv.best_score_, DT_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4faaa16",
   "metadata": {},
   "source": [
    "## 2. Chefboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "485255e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chefboost import Chefboost as chef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef0707db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "def ChefBoostCrossValidation(train_set, test_set, algorithms, K, target_label):\n",
    "\n",
    "    # initialization\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    f1_score_all = []\n",
    "    #K-fold\n",
    "    kf = KFold(n_splits=K)\n",
    "#     kf.get_n_splits(train_set)\n",
    "\n",
    "    for algo in algorithms:   # for each algo, run k-fold CV\n",
    "        \n",
    "        config = {'algorithm': algo}\n",
    "                  \n",
    "        f1list_each_algo = []\n",
    "\n",
    "        for train_idx, test_idx in kf.split(train_set):  # run k-fold cross-validation\n",
    "\n",
    "            train = train_set.iloc[train_idx]   \n",
    "                  \n",
    "            x_train = train.drop(columns=target_label)\n",
    "            y_train = train[target_label]\n",
    "\n",
    "            test = train_set.iloc[test_idx]\n",
    "            x_test = test.drop(columns=target_label)\n",
    "            y_test = test[target_label]\n",
    "                  \n",
    "            model_chef = chef.fit(train, config=config, target_label='Sales')\n",
    "            # for each train set the K-fold selected, apply and fit a new model\n",
    "\n",
    "            # then for each newly-trained model, run prediction and compute f1-score\n",
    "                  # chefboost can only pass one row at a time when predicting\n",
    "            for index, row in x_test.iterrows():   # for each row in test set\n",
    "                pred_label = chef.predict(model_chef, row)  # run prediction\n",
    "\n",
    "                # compute confusion matrix\n",
    "                if pred_label == 1:\n",
    "\n",
    "                    if y_test[index] == 1:\n",
    "                        TP += 1\n",
    "\n",
    "                    elif y_test[index] == 0:\n",
    "                        FP += 1\n",
    "\n",
    "                if pred_label == 0:\n",
    "\n",
    "                    if y_test[index] == 1:\n",
    "                        FN += 1\n",
    "\n",
    "                    elif y_test[index] == 0:\n",
    "                        TN += 1\n",
    "\n",
    "            confusion_matrix = np.array([[TP, FP],[FN, TN]])\n",
    "            TPR_recall = TP / (TP + FN)\n",
    "            precision = TP / (TP + FP)\n",
    "            f1 = 2 * (precision * TPR_recall) / (precision + TPR_recall)\n",
    "                  # this is the f1-score of one model using a specific algorithm\n",
    "            f1list_each_algo.append(f1)\n",
    "                  # store the score in a list\n",
    "                  \n",
    "        algo_f1 = np.average(f1list_each_algo) \n",
    "                  # after completing k-fold CV for one depth, jump out of the loop \n",
    "                  # and compute the average of all f1-scores for that algorithm\n",
    "        f1_score_all.append(algo_f1)\n",
    "                  \n",
    "    f1_dict = {\n",
    "        'algorithms': algorithms,\n",
    "        'f1_score': f1_score_all\n",
    "    }\n",
    "    df_f1 = pd.DataFrame(f1_dict)\n",
    "    arg_best = np.argsort(f1_score_all)[-1]\n",
    "    best_algo = algorithms[arg_best]\n",
    "    best_f1 = np.sort(f1_score_all)[-1]\n",
    "        \n",
    "    return best_algo, best_f1, df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9526547e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "WARNING: You set the algorithm to  C4.5  but the Decision column of your data set has non-object type.\n",
      "That's why, the algorithm is set to Regression to handle the data set.\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  3.493199110031128  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0647163120567376\n",
      "MSE:  0.05097517730496453\n",
      "RMSE:  0.22577683075321198\n",
      "RAE:  0.37540827448129\n",
      "RRSE:  0.46988560699401155\n",
      "Mean:  0.3617021276595745\n",
      "MAE / Mean:  17.8921568627451 %\n",
      "RMSE / Mean:  62.42065320824095 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  3.073704957962036  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.12677304964539007\n",
      "MSE:  0.08732269503546099\n",
      "RMSE:  0.295504137086879\n",
      "RAE:  0.45877018807904835\n",
      "RRSE:  0.5997603769110708\n",
      "Mean:  0.4148936170212766\n",
      "MAE / Mean:  30.55555555555556 %\n",
      "RMSE / Mean:  71.22407406709392 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  2.456028938293457  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0523049645390071\n",
      "MSE:  0.03679078014184397\n",
      "RMSE:  0.19180922851063234\n",
      "RAE:  0.3287444549595729\n",
      "RRSE:  0.40478696441355394\n",
      "Mean:  0.3404255319148936\n",
      "MAE / Mean:  15.364583333333334 %\n",
      "RMSE / Mean:  56.343960874998245 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "WARNING: You set the algorithm to  ID3  but the Decision column of your data set has non-object type.\n",
      "That's why, the algorithm is set to Regression to handle the data set.\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  2.865651845932007  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0647163120567376\n",
      "MSE:  0.05097517730496453\n",
      "RMSE:  0.22577683075321198\n",
      "RAE:  0.37540827448129\n",
      "RRSE:  0.46988560699401155\n",
      "Mean:  0.3617021276595745\n",
      "MAE / Mean:  17.8921568627451 %\n",
      "RMSE / Mean:  62.42065320824095 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  3.015012741088867  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.12677304964539007\n",
      "MSE:  0.08732269503546099\n",
      "RMSE:  0.295504137086879\n",
      "RAE:  0.45877018807904835\n",
      "RRSE:  0.5997603769110708\n",
      "Mean:  0.4148936170212766\n",
      "MAE / Mean:  30.55555555555556 %\n",
      "RMSE / Mean:  71.22407406709392 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  2.4575560092926025  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0523049645390071\n",
      "MSE:  0.03679078014184397\n",
      "RMSE:  0.19180922851063234\n",
      "RAE:  0.3287444549595729\n",
      "RRSE:  0.40478696441355394\n",
      "Mean:  0.3404255319148936\n",
      "MAE / Mean:  15.364583333333334 %\n",
      "RMSE / Mean:  56.343960874998245 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "WARNING: You set the algorithm to  CART  but the Decision column of your data set has non-object type.\n",
      "That's why, the algorithm is set to Regression to handle the data set.\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  2.8816869258880615  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0647163120567376\n",
      "MSE:  0.05097517730496453\n",
      "RMSE:  0.22577683075321198\n",
      "RAE:  0.37540827448129\n",
      "RRSE:  0.46988560699401155\n",
      "Mean:  0.3617021276595745\n",
      "MAE / Mean:  17.8921568627451 %\n",
      "RMSE / Mean:  62.42065320824095 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  3.1659939289093018  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.12677304964539007\n",
      "MSE:  0.08732269503546099\n",
      "RMSE:  0.295504137086879\n",
      "RAE:  0.45877018807904835\n",
      "RRSE:  0.5997603769110708\n",
      "Mean:  0.4148936170212766\n",
      "MAE / Mean:  30.55555555555556 %\n",
      "RMSE / Mean:  71.22407406709392 %\n",
      "[INFO]:  4 CPU cores will be allocated in parallel running\n",
      "Regression  tree is going to be built...\n",
      "-------------------------\n",
      "finished in  2.6229701042175293  seconds\n",
      "-------------------------\n",
      "Evaluate  train set\n",
      "-------------------------\n",
      "MAE:  0.0523049645390071\n",
      "MSE:  0.03679078014184397\n",
      "RMSE:  0.19180922851063234\n",
      "RAE:  0.3287444549595729\n",
      "RRSE:  0.40478696441355394\n",
      "Mean:  0.3404255319148936\n",
      "MAE / Mean:  15.364583333333334 %\n",
      "RMSE / Mean:  56.343960874998245 %\n"
     ]
    }
   ],
   "source": [
    "algorithms = ['C4.5', 'ID3', 'CART']\n",
    "K=3\n",
    "target_label = 'Sales'\n",
    "chef_result = ChefBoostCrossValidation(train1, test1, algorithms, K, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8172da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C4.5',\n",
       " 0.6539487607908661,\n",
       "   algorithms  f1_score\n",
       " 0       C4.5  0.653949\n",
       " 1        ID3  0.645775\n",
       " 2       CART  0.644683)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chef_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9e25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e9696c",
   "metadata": {},
   "source": [
    "## 5.3 KNN\n",
    "### Algorithm\n",
    "1. calculate distance (Euclidean, Manhattan)\n",
    "1. define K, find K nearest neighbors\n",
    "1. using voting to define the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6ff699e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate didstance for each test points\n",
    "def distance(train, test, cal_type):\n",
    "    \n",
    "    index = np.arange(test.shape[0])\n",
    "    distance_dict = {}\n",
    "    \n",
    "    if cal_type == 'Manhattan':\n",
    "        \n",
    "        for i in index: # iterate each row of test set\n",
    "            distance_list = []\n",
    "            l_test = test.iloc[i]\n",
    "            for j in list(train.index): \n",
    "                # iterate each row of train set and compute distance w.r.t. each test point\n",
    "                l_train = train.iloc[j]\n",
    "                distance = abs(sum(l_test-l_train))\n",
    "                distance_list.append(distance)\n",
    "            distance_dict[i] = distance_list\n",
    "            \n",
    "    elif cal_type == 'Euclidean':\n",
    "        \n",
    "        for i in index:\n",
    "            distance_list = []\n",
    "            l_test = test.iloc[i]\n",
    "            for j in list(train.index):\n",
    "                l_train = train.iloc[j]\n",
    "                distance = mt.sqrt(sum(l_train-l_test)**2)\n",
    "                distance_list.append(distance)\n",
    "            distance_dict[i] = distance_list\n",
    "            \n",
    "    else:\n",
    "        return 'Type not found.'\n",
    "        distance_dict = {np.na}\n",
    "    \n",
    "    return distance_dict\n",
    "\n",
    "\n",
    "\n",
    "# find K nearest neighbors according to the defined K parameter\n",
    "def KNNClassifier(train, test, K, cal_type):\n",
    "    \n",
    "    dis = distance(train, test, cal_type)\n",
    "\n",
    "    df_distance = pd.DataFrame(dis).T # return distance result as a dataframe\n",
    "    class_result = []\n",
    "    # the following lines decide which category gets the most votes and return results\n",
    "    for index, row in df_distance.iterrows():\n",
    "        \n",
    "        args = np.argsort(row) # return the argument(index) of the K most nearest points\n",
    "        Knns = [train['Sales'].iloc[j] for j in args[:K]]\n",
    "           #for each index, return the category in training set\n",
    "        \n",
    "        if Knns.count('Yes') >= Knns.count('No'):  # most votes\n",
    "            result = 1\n",
    "            \n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        class_result.append(result) \n",
    "\n",
    "#         class_result[index] = class_each_row\n",
    "#         df_class_result = pd.DataFrame(class_result).T # transform to dataframe\n",
    "#         df_class_result['True_Urban'] = test1['urban_Yes']\n",
    "#         df_class_result['True_US'] = test1['us_Yes']\n",
    "        # add the actual classification to the last two columns\n",
    "\n",
    "    return class_result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defae2ab",
   "metadata": {},
   "source": [
    "### Tuning parameters (K and distance metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0b1e4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParamTuning(train, test, K_list, dis_metrics, target_label):\n",
    "    \n",
    "    compare = {}\n",
    "    y_true = test[target_label]\n",
    "    \n",
    "    for d in dis_metrics:\n",
    "        inner = {}\n",
    "        for k in K_list:\n",
    "            y_pred = KNNClassifier(train, test, k, d)\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "            inner[f'k={k}'] = f1\n",
    "        \n",
    "        compare[f'distance_metric={d}'] = inner\n",
    "    df_compare = pd.DataFrame(compare)\n",
    "    max_f1 = df_compare.max()\n",
    "\n",
    "    return max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1ab45b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_list = np.arange(3,7)\n",
    "dis_metrics = ['Manhattan', 'Euclidean']\n",
    "knn_best = ParamTuning(train1, test1, K_list, dis_metrics, target_label='Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b3545bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_metric=Manhattan    0.666667\n",
       "distance_metric=Euclidean    0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a97b40",
   "metadata": {},
   "source": [
    "## 5.3 Best preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4738950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: 0.737807881773399 {'max_depth': 8, 'min_samples_leaf': 5}\n",
      "ChefBoost: C4.5 0.6539487607908661\n",
      "KNN: distance_metric=Manhattan    0.666667\n",
      "distance_metric=Euclidean    0.666667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "print('DecisionTree:', DT_gscv.best_score_, DT_gscv.best_params_)\n",
    "\n",
    "# ChefBoost\n",
    "print('ChefBoost:', chef_result[0], chef_result[1])\n",
    "\n",
    "# KNN\n",
    "print('KNN:', knn_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e1e83",
   "metadata": {},
   "source": [
    "Therefore, DecisionTreeClassifier performed the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a508d4c",
   "metadata": {},
   "source": [
    "## 5.4 \n",
    "As its name implies, LOOCV only keeps one point as the validation set while tuning parameters.\n",
    "\n",
    "If K=n (n=total number of training points), then LOOCV equals K-fold CV.   \n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. High variance compared with k-fold. The training sets of LOOCV greatly overlap with one another. Therefore, the prediction will be highly correlated and interdependent, which increases variance.\n",
    "\n",
    "1. Computationally expensive. Every time it needs to train on n-1 datasets and test on one set, which is more time-consuming than k-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b049e",
   "metadata": {},
   "source": [
    "## 5.5\n",
    "\n",
    "I think f1 score and accuracy (misclassification error) are both good metrics for this specific dataset. Since f1 score is the Hamonic average of precision and recall, it can better return the prediction preformance on imbalanced dataset. However, in this problem, dataset is balanced (equal number of 1s and 0s in test set), so both f1 and accuracy are plausible.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d1ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
